{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e32ffff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCNNs, like neural networks, are made up of neurons with learnable weights and biases. \\nEach neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output.\\nThe whole network has a loss function and all the tips and tricks that we developed for neural networks still apply on CNNs.\\n\\nA convolution is an operation that changes a function into something else. \\nWe do convolutions so that we can transform the original function into a form to get more information.\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CNNs, like neural networks, are made up of neurons with learnable weights and biases. \n",
    "Each neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output.\n",
    "The whole network has a loss function and all the tips and tricks that we developed for neural networks still apply on CNNs.\n",
    "\n",
    "A convolution is an operation that changes a function into something else. \n",
    "We do convolutions so that we can transform the original function into a form to get more information.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c2430c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required modules\n",
    "\n",
    "import numpy as np # numpy for working with images as 3D arrays\n",
    "import keras # open-source neural network library\n",
    "from keras import backend as k\n",
    "from keras.datasets import mnist # importing the mnist datatset\n",
    "from keras.models import Model # import the Model function for training and testing the model\n",
    "\n",
    "# A Dense layer feeds all outputs from the previous layer to all its neurons, each neuron providing one output to the next layer.\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "# Pooling helps the layer generalize because it effectively combines several values into a single one, this decreases the chance of overfitting\n",
    "# Dropout layer initializes a set of inputs to zero, to reduce Overfitting.\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e69b4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the datasets into 60000 train images and 10000 test images\n",
    "# x and y are input and output arrays\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca5041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# to find dimensions of 3D x_train and x_test\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa3ab43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d792bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we initialize the pixel values of each input image, and then we reshape the training array for the same\n",
    "\n",
    "image_rows, image_cols=28, 28\n",
    "\n",
    "if k.image_data_format() == 'channels_first': \n",
    "\n",
    "  # the number of training data inputs is 60000, which is returned by x_train.shape[0]\n",
    "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) \n",
    "\n",
    "  # the number of training data inputs is 10000, which is returned by x_train.shape[0]\n",
    "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) \n",
    "\n",
    "  # inpx contains dimensions of the arrays\n",
    "  inpx = (1, image_rows, image_cols) \n",
    "\n",
    "else: \n",
    "\n",
    "  x_train = x_train.reshape(x_train.shape[0], image_rows, image_cols, 1) \n",
    "  \n",
    "  x_test = x_test.reshape(x_test.shape[0], image_rows, image_cols, 1) \n",
    "  \n",
    "  inpx = (image_rows, image_cols, 1) \n",
    "\n",
    "# we need to convert each numerical value to the closest float value, such that large terms are reduced to smaller terms\n",
    "\n",
    "x_train = x_train.astype('float32') \n",
    "x_test = x_test.astype('float32') \n",
    "\n",
    "# to normalize all the values \n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbed2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7941e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.np_utils.to_categorical(y_train) \n",
    "y_test = keras.utils.np_utils.to_categorical(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53084d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpx = Input(shape=inpx) \n",
    "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx) \n",
    "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1) \n",
    "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2) \n",
    "layer4 = Dropout(0.5)(layer3) \n",
    "layer5 = Flatten()(layer4) \n",
    "layer6 = Dense(250, activation='sigmoid')(layer5) \n",
    "layer7 = Dense(10, activation='softmax')(layer6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96cceaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f9da3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "120/120 [==============================] - 44s 367ms/step - loss: 0.4955 - accuracy: 0.8585\n",
      "Epoch 2/8\n",
      "120/120 [==============================] - 45s 373ms/step - loss: 0.1203 - accuracy: 0.9668\n",
      "Epoch 3/8\n",
      "120/120 [==============================] - 45s 377ms/step - loss: 0.0771 - accuracy: 0.9785\n",
      "Epoch 4/8\n",
      "120/120 [==============================] - 45s 378ms/step - loss: 0.0608 - accuracy: 0.9825\n",
      "Epoch 5/8\n",
      "120/120 [==============================] - 45s 379ms/step - loss: 0.0491 - accuracy: 0.9862\n",
      "Epoch 6/8\n",
      "120/120 [==============================] - 46s 385ms/step - loss: 0.0407 - accuracy: 0.9886\n",
      "Epoch 7/8\n",
      "120/120 [==============================] - 46s 380ms/step - loss: 0.0351 - accuracy: 0.9901\n",
      "Epoch 8/8\n",
      "120/120 [==============================] - 46s 382ms/step - loss: 0.0333 - accuracy: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244e6aeea90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the Model function in keras backend to assemble all layers of the model\n",
    "\n",
    "model = Model([inpx], layer7)\n",
    "\n",
    "# defining the necessary optimizer, loss function, for receiving the accuracy and loss results\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "\t\t\tloss=keras.losses.categorical_crossentropy, \n",
    "\t\t\tmetrics=['accuracy']) \n",
    "\n",
    "# dividing the model into 8 epochs and giving each epoch a batch size of 500 elements\n",
    "\n",
    "model.fit(x_train, y_train, epochs=8, batch_size=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8831008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 250)               1024250   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                2510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,576\n",
      "Trainable params: 1,045,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# to show summary of model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e605972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# to show the sample working of model, by using matplotlib to plot the number and its corresponding output.\n",
    "import matplotlib.pyplot as plt\n",
    "print(np.shape(x_train[0]))\n",
    "\n",
    "inp=x_test[0]\n",
    "outp=y_test[0]\n",
    "\n",
    "inp2=inp.reshape(28,28)\n",
    "\n",
    "plt.imshow(inp2, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c253c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
